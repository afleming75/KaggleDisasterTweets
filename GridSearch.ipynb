{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn import feature_extraction, linear_model, model_selection, preprocessing\n",
    "\n",
    "# WordCloud and matplotlib for visualization\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO DO\n",
    "\n",
    "- assigning keywords to missing keyword labels - DONE\n",
    "- remove symbols (#, \".. - DONE\n",
    "- remove links - DONE\n",
    "- validation\n",
    "- make slides - IN PROCESS\n",
    "- TFIDF, LSA, LSTM / RNNs, the list is long\n",
    "- try different classifiers\n",
    "- reading discussion board for inspiration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"preprocessed_train_data.csv\", index_col = 0)\n",
    "test = pd.read_csv(\"preprocessed_test_data.csv\", index_col = 0)\n",
    "\n",
    "trained_tweets = train['keyword']+train['text']\n",
    "test_tweets = test['keyword']+test['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    earthquak  deed reason earthquak may allah for...\n",
       "1     forest fire  forest fire near la rang ask canada\n",
       "2    evacu  resid ask shelter place notifi offic ev...\n",
       "3    wildfir  peopl receiv wildfir evacu order cali...\n",
       "4    wildfir  got sent photo rubi alaska smoke wild...\n",
       "dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                      crash  happen terribl car crash\n",
       "1    earthquak  heard earthquak differ citi stay sa...\n",
       "2    forest fire  forest fire spot pond gees flee a...\n",
       "3            apocalyps  apocalyps light spokan wildfir\n",
       "4          typhoon  typhoon soudelor kill china taiwan\n",
       "dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding and Vectorizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import category_encoders as ce\n",
    "\n",
    "# # Target encoding\n",
    "# features = ['keyword']\n",
    "# encoder = ce.TargetEncoder(cols=features)\n",
    "# encoder.fit(train[features],train['target'])\n",
    "\n",
    "# train = train.join(encoder.transform(train[features]).add_suffix('_target'))\n",
    "# test = test.join(encoder.transform(test[features]).add_suffix('_target'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(trained_tweets, train['target'].values, \n",
    "        train_size = 0.80, test_size = 0.20, random_state = 12, shuffle=True) # We have split train-test dataset using 80:20 ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6090, 48864) (1523, 48864)\n"
     ]
    }
   ],
   "source": [
    "#precompute vectorized representations\n",
    "word_vectorizer = TfidfVectorizer(\n",
    "    analyzer='word',\n",
    "    stop_words='english',\n",
    "    ngram_range=(1, 3),\n",
    "    lowercase=True,\n",
    "    min_df=5,\n",
    "    max_features=30000)\n",
    "\n",
    "char_vectorizer = TfidfVectorizer(\n",
    "    analyzer='char',\n",
    "    stop_words='english',\n",
    "    ngram_range=(3, 6),\n",
    "    lowercase=True,\n",
    "    min_df=5,\n",
    "    max_features=50000)\n",
    "\n",
    "vectorizer = FeatureUnion([('word_vectorizer', word_vectorizer),  ('char_vectorizer', char_vectorizer)])\n",
    "vectorizer.fit(X_train)\n",
    "\n",
    "X_train_vectors = vectorizer.transform(X_train).toarray()\n",
    "X_test_vectors = vectorizer.transform(X_test).toarray()\n",
    "print(X_train_vectors.shape, X_test_vectors.shape)\n",
    "\n",
    "#X_train_text = X_train.tolist()\n",
    "#X_test_text = X_test.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model_params = {\n",
    "    'svm': {\n",
    "        'model': svm.SVC(gamma='auto'),\n",
    "        'params' : {\n",
    "            'C': [1,10,20],\n",
    "            'kernel': ['rbf','linear']\n",
    "        }  \n",
    "    },\n",
    "    'random_forest': {\n",
    "        'model': RandomForestClassifier(),\n",
    "        'params' : {\n",
    "            'n_estimators': [1,5,10]\n",
    "        }\n",
    "    },\n",
    "    'logistic_regression' : {\n",
    "        'model': LogisticRegression(solver='liblinear',multi_class='auto'),\n",
    "        'params': {\n",
    "            'C': [1,5,10]\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "scores = []\n",
    "\n",
    "for model_name, mp in model_params.items():\n",
    "    clf =  GridSearchCV(mp['model'], mp['params'], cv=5, return_train_score=False)\n",
    "    clf.fit(X_train_vectors, y_train)\n",
    "    scores.append({\n",
    "        'model': model_name,\n",
    "        'best_score': clf.best_score_,\n",
    "        'best_params': clf.best_params_\n",
    "    })\n",
    "    \n",
    "df = pd.DataFrame(scores,columns=['model','best_score','best_params'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
